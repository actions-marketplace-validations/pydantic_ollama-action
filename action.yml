name: Run ollama server
description: Run an ollama server with the model you provide

inputs:
  model:
    description: The model to run

runs:
  using: composite
  steps:
    - name: Cache Ollama Install
      id: cache-ollama
      uses: actions/cache@v4
      with:
        path: /tmp/ollama-run
        key: ollama-${{ hashFiles('install-ollama.sh') }}

    - name: Install Ollama
      if: steps.cache-ollama.outputs.cache-hit != 'true'
      run: ./install-ollama.sh
      shell: bash

    - name: Start Ollama
      run: ./start-ollama.sh
      shell: bash

    - name: Pull Model
      run: ollama pull ${{ inputs.model }}
      shell: bash
