name: Run ollama server
description: Run an ollama server with the model you provide

inputs:
  model:
    description: The model to run
    required: true
  cache-key:
    description: The cache key to use
    required: false
    default: ''

runs:
  using: composite
  steps:
    - id: cache-ollama-install
      uses: actions/cache@v4
      with:
        path: ./.ollama-install
        key: ollama-install-${{ inputs.cache-key }}-${{ hashFiles('install-ollama.sh') }}

    - id: cache-ollama-models
      uses: actions/cache@v4
      with:
        path: ~/.ollama
        key: ollama-models-${{ inputs.cache-key }}

    - if: steps.cache-ollama-install.outputs.cache-hit != 'true'
      run: '${GITHUB_ACTION_PATH}install-ollama.sh'
      shell: bash

    - run: echo $(pwd)/.ollama-install/bin >> $GITHUB_PATH
      shell: bash

    - run: ollama start &
      shell: bash

    - run: ollama --version
      shell: bash

    - if: steps.cache-ollama-models.outputs.cache-hit != 'true'
      run: ollama pull ${{ inputs.model }}
      shell: bash
